{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "RAJ RAUNAK KUMAR 20HCS4148"
      ],
      "metadata": {
        "id": "ougLhdvPbSVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Digits dataset ko load karna\n",
        "digits = load_digits()  # Digits dataset ko load karna\n",
        "X = digits.data  # Features (images as flattened arrays)\n",
        "y = digits.target  # Labels (digits 0-9)\n",
        "\n",
        "# Dataset ko 70-30 ratio mein training aur testing sets mein divide karna\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)  # 70-30 split\n",
        "\n",
        "# Features ko normalize karna (for numerical stability)\n",
        "X_train = X_train / 16  # Normalize to 0-1\n",
        "X_test = X_test / 16  # Normalize to 0-1\n"
      ],
      "metadata": {
        "id": "qF8x2eqBb992"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single hidden layer neural network ka class\n",
        "class TwoLayerANN:\n",
        "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
        "        self.input_size = input_size  # Input size\n",
        "        self.hidden_size = hidden_size  # Hidden layer size\n",
        "        self.output_size = output_size  # Output size\n",
        "        self.learning_rate = learning_rate  # Learning rate\n",
        "\n",
        "        # Randomly initialize weights and biases\n",
        "        self.hidden_weights = np.random.randn(input_size, hidden_size)  # Weights for hidden layer\n",
        "        self.hidden_bias = np.zeros(hidden_size)  # Bias for hidden layer\n",
        "\n",
        "        self.output_weights = np.random.randn(hidden_size, output_size)  # Weights for output layer\n",
        "        self.output_bias = np.zeros(output_size)  # Bias for output layer\n",
        "\n",
        "    def relu(self, x):\n",
        "        # Relu activation function\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def softmax(self, x):\n",
        "        # Softmax activation function\n",
        "        exps = np.exp(x - np.max(x))  # Stabilize with subtracting max\n",
        "        return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Forward pass through the network\n",
        "        self.hidden_layer = self.relu(np.dot(X, self.hidden_weights) + self.hidden_bias)  # Hidden layer\n",
        "        self.output_layer = self.softmax(np.dot(self.hidden_layer, self.output_weights) + self.output_bias)  # Output layer\n",
        "        return self.output_layer\n",
        "\n",
        "    def backward(self, X, y):\n",
        "        # Backward pass for gradients\n",
        "        m = X.shape[0]  # Number of samples\n",
        "\n",
        "        # Derivative of softmax cross-entropy loss\n",
        "        output_error = self.output_layer  # Copy output\n",
        "        output_error[range(m), y] -= 1  # Subtract correct class (1-hot-like)\n",
        "\n",
        "        # Gradients for output layer\n",
        "        dW_out = np.dot(self.hidden_layer.T, output_error) / m\n",
        "        dB_out = np.sum(output_error, axis=0) / m\n",
        "\n",
        "        # Gradients for hidden layer\n",
        "        hidden_error = np.dot(output_error, self.output_weights.T) * (self.hidden_layer > 0)  # Relu derivative\n",
        "        dW_hidden = np.dot(X.T, hidden_error) / m\n",
        "        dB_hidden = np.sum(hidden_error, axis=0) / m\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.output_weights -= self.learning_rate * dW_out\n",
        "        self.output_bias -= self.learning_rate * dB_out\n",
        "        self.hidden_weights -= self.learning_rate * dW_hidden\n",
        "        self.hidden_bias -= self.learning_rate * dB_hidden\n",
        "\n",
        "    def train(self, X, y, epochs=10, batch_size=32):\n",
        "        # Training the neural network\n",
        "        m = X.shape[0]  # Total samples\n",
        "        for _ in range(epochs):\n",
        "            for i in range(0, m, batch_size):  # Mini-batches\n",
        "                X_batch = X[i:i + batch_size]\n",
        "                y_batch = y[i:i + batch_size]\n",
        "                self.forward(X_batch)  # Forward pass\n",
        "                self.backward(X_batch, y_batch)  # Backward pass\n"
      ],
      "metadata": {
        "id": "hvf9MWOrb91h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN model ko initialize karna with specific sizes\n",
        "ann = TwoLayerANN(input_size=64, hidden_size=32, output_size=10, learning_rate=0.01)  # Input, hidden, output size\n",
        "\n",
        "# ANN model ko train karna\n",
        "ann.train(X_train, y_train, epochs=20, batch_size=32)  # Train for 20 epochs\n",
        "\n",
        "# Testing set par predictions generate karna\n",
        "y_pred = ann.forward(X_test)  # Forward pass for testing data\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert softmax to class labels\n",
        "\n",
        "# Accuracy ko calculate karna\n",
        "test_accuracy = accuracy_score(y_test, y_pred_classes)  # Accuracy on test set\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")  # Print test accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4vsxSUNb9qQ",
        "outputId": "2f4a2ede-5daf-4358-9ed0-56fad724472a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.63\n"
          ]
        }
      ]
    }
  ]
}